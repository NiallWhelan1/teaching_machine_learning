{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Questions:\n",
    "1. NN Architecture/Layers: \n",
    "    - Really good conversation withs several approaches: https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw#:~:text=Like%20the%20Input%20layer%2C%20every,by%20the%20chosen%20model%20configuration.\n",
    "    - Article on approach to number of layers: https://machinelearningmastery.com/how-to-configure-the-number-of-layers-and-nodes-in-a-neural-network/\n",
    "    - Overall this is an area of much debate in data science and there is no one approach fits all.\n",
    "    \n",
    "    100 - Input Layer\n",
    "    \n",
    "    Hidden Layers: 128/64/32/16\n",
    "    \n",
    "\n",
    "2. Activation Functions: \n",
    "    - https://medium.com/the-theory-of-everything/understanding-activation-functions-in-neural-networks-9491262884e0\n",
    "    - Relu: Because of the horizontal line in ReLu( for negative X ), the gradient can go towards 0. For activations in that region of ReLu, gradient will be 0 because of which the weights will not get adjusted during descent. That means, those neurons which go into that state will stop responding to variations in error/ input ( simply because gradient is 0, nothing changes ). This is called dying ReLu problem. This problem can cause several neurons to just die and not respond making a substantial part of the network passive. There are variations in ReLu to mitigate this issue by simply making the horizontal line into non-horizontal component . for example y = 0.01x for x<0 will make it a slightly inclined line rather than horizontal line. This is leaky ReLu. There are other variations too. The main idea is to let the gradient be non zero and recover during training eventually.\n",
    "    \n",
    "    \n",
    "3. Loss Functions: \n",
    "    - Article on each loss function: https://analyticsindiamag.com/loss-functions-in-deep-learning-an-overview/\n",
    "    - MSE (Regression): Mean Squared Error is the mean of squared differences between the actual and predicted value. If the difference is large the model will penalize it as we are computing the squared difference.\n",
    "    - Cross Entropy (Binary Classification): It gives the probability value between 0 and 1 for a classification task. Cross-Entropy calculates the average difference between the predicted and actual probabilities.\n",
    "    \n",
    "    \n",
    "4. Optimizers: \n",
    "    - https://towardsdatascience.com/optimizers-for-training-neural-network-59450d71caf6\n",
    "    - ADAM optimizer is the current \"best of breed\" - is more dynamic than traditional optimizers such as Stochastic Gradient Descent.\n",
    "    \n",
    "\n",
    "Last peice of advise: KISS principle - https://en.wikipedia.org/wiki/KISS_principle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4ljrXbm43CuG"
   },
   "source": [
    "## Introduction to Neural Networks - Fraud Detection\n",
    "\n",
    "Nilson reports that U.S. card fraud (credit, debt, etc) was reportedly 9 billion dollars in 2016 and expected to increase to 12 billion dollars by 2020. For perspective, in 2017 both PayPal's and Mastercard's revenue was only $10.8 billion each.\n",
    "\n",
    "\n",
    "**Objective:** In this session, given the credit card transactions, we will build a simple neural network (i.e., Multilayer perceptrons) for Fraud Detection using Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ilr-y66cDLn7"
   },
   "source": [
    "This notebooks covers,\n",
    "\n",
    "1. Creating a Model\n",
    "\n",
    "2. Adding Layers\n",
    "\n",
    "3. Activations\n",
    "\n",
    "4. Optimizers and Loss functions\n",
    "\n",
    "5. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g3u3Z-GA1dFK"
   },
   "source": [
    "### Dataset Description\n",
    "\n",
    "The datasets contains transactions made by credit cards in September 2013 by european cardholders. This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
    "\n",
    "It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, the original features and more background information about the data is not provided. Features V1, V2, ... V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.\n",
    "\n",
    "Source: https://www.kaggle.com/mlg-ulb/creditcardfraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "vOYk8UicQrZ5",
    "outputId": "974a82f8-b975-49fe-b0d1-6c12e375a0bb"
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflow==2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "H79BpACkblay",
    "outputId": "fab8c838-6558-431d-d087-f2f3c9de655d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Ro7A1N5y6Hh"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, precision_recall_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "spJIiLsDeP2K"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive/')\n",
    "#project_path = '/content/drive/My Drive/Colab Notebooks/'\n",
    "#dataset_file = project_path + 'creditcard.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OM0t4RaJe10y"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "colab_type": "code",
    "id": "LzmnvBMKe13i",
    "outputId": "ee87fbdd-3249-4dbd-dc52-56a91167bd26"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XYR1bqVjr74v"
   },
   "outputs": [],
   "source": [
    "data = data.drop(\"Time\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8jSUoRdjffH1"
   },
   "outputs": [],
   "source": [
    "X_data = data.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cI3wN8jqftKw",
    "outputId": "c5873a8f-bb7f-4585-f727-aff4cbfc7d6b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 29)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "colab_type": "code",
    "id": "lNVt9nlwr4be",
    "outputId": "978198d9-ae57-404e-8558-54943481f552"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V20       V21       V22       V23  \\\n",
       "0  0.098698  0.363787  0.090794  ...  0.251412 -0.018307  0.277838 -0.110474   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.069083 -0.225775 -0.638672  0.101288   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.524980  0.247998  0.771679  0.909412   \n",
       "3  0.377436 -1.387024 -0.054952  ... -0.208038 -0.108300  0.005274 -0.190321   \n",
       "4 -0.270533  0.817739  0.753074  ...  0.408542 -0.009431  0.798278 -0.137458   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Amount  \n",
       "0  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62  \n",
       "1 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69  \n",
       "2 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66  \n",
       "3 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50  \n",
       "4  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Av0SeUasfxdd"
   },
   "outputs": [],
   "source": [
    "y_data = data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PxJAWm1pf2Pp",
    "outputId": "017959c2-1d23-41f8-a008-2ef741115dff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HeY6L0Pd1ZuF"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size = 0.2, random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MRNMm_VFf1py"
   },
   "outputs": [],
   "source": [
    "X_train = preprocessing.normalize(X_train)\n",
    "X_test = preprocessing.normalize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "tTq5DsKV1ayv",
    "outputId": "48f5e6bb-fd2c-4f88-bae6-5a8c9d2dd64c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(227845, 29)\n",
      "(56962, 29)\n",
      "(227845,)\n",
      "(56962,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rK65fuEW1rNR"
   },
   "source": [
    "### Creating a model\n",
    "\n",
    "Keras model object can be created with Sequential class\n",
    "\n",
    "At the outset, the model is empty per se. It is completed by adding additional layers and compilation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tf5xPvFh1vpI"
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PY-sWPLV1ymZ"
   },
   "source": [
    "### Adding layers [layers and activations]\n",
    "\n",
    "Keras layers can be added to the model\n",
    "\n",
    "Adding layers are like stacking lego blocks one by one\n",
    "\n",
    "It should be noted that as this is a classification problem, sigmoid layer (softmax for multi-class problems) should be added\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "29/64/32/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wSW0d2sX1w4Z"
   },
   "outputs": [],
   "source": [
    "model.add(Dense(64, input_shape = (29,), activation = 'relu')) # 1st hidden layer - 64\n",
    "model.add(Dense(32, activation = 'tanh')) # 2nd hidden layer\n",
    "\n",
    "model.add(Dense(1, activation = 'sigmoid')) # Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hk3MOIy12SU_"
   },
   "source": [
    "### Model compile [optimizers and loss functions]\n",
    "\n",
    "Keras model should be \"compiled\" prior to training\n",
    "\n",
    "Types of loss (function) and optimizer should be designated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7QyeAsLo2Nj0"
   },
   "outputs": [],
   "source": [
    "sgd = optimizers.Adam(lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f4hkSuwa2aFR"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = sgd, \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary Cross entropy: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/categorical-crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0pgrwczG2dMz"
   },
   "source": [
    "### Summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "KnQIxKfn2baE",
    "outputId": "5bcc1421-6ca7-46e6-b92d-9aceb9422b43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 64)                1920      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 4,033\n",
      "Trainable params: 4,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GPP-Q5O-2iel"
   },
   "source": [
    "### Training [Forward pass and Backpropagation]\n",
    "\n",
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "colab_type": "code",
    "id": "Nbj63utw2fHI",
    "outputId": "2aca85cb-acf9-4a7c-ed4e-d01605443970"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 227845 samples\n",
      "Epoch 1/10\n",
      "227845/227845 [==============================] - 3s 11us/sample - loss: 0.0519 - accuracy: 0.9980\n",
      "Epoch 2/10\n",
      "227845/227845 [==============================] - 2s 7us/sample - loss: 0.0075 - accuracy: 0.9983\n",
      "Epoch 3/10\n",
      "227845/227845 [==============================] - 2s 8us/sample - loss: 0.0065 - accuracy: 0.9985\n",
      "Epoch 4/10\n",
      "227845/227845 [==============================] - 2s 8us/sample - loss: 0.0055 - accuracy: 0.9990\n",
      "Epoch 5/10\n",
      "227845/227845 [==============================] - 2s 8us/sample - loss: 0.0051 - accuracy: 0.9990\n",
      "Epoch 6/10\n",
      "227845/227845 [==============================] - 2s 8us/sample - loss: 0.0048 - accuracy: 0.9990\n",
      "Epoch 7/10\n",
      "227845/227845 [==============================] - 2s 9us/sample - loss: 0.0045 - accuracy: 0.9991\n",
      "Epoch 8/10\n",
      "227845/227845 [==============================] - 2s 9us/sample - loss: 0.0043 - accuracy: 0.9991\n",
      "Epoch 9/10\n",
      "227845/227845 [==============================] - 2s 9us/sample - loss: 0.0041 - accuracy: 0.9991\n",
      "Epoch 10/10\n",
      "227845/227845 [==============================] - 2s 9us/sample - loss: 0.0040 - accuracy: 0.9992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fba026eead0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, \n",
    "          y_train.values, \n",
    "          batch_size = 700, \n",
    "          epochs = 10, \n",
    "          verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lLPxzhrv2sxz"
   },
   "source": [
    "### Evaluation\n",
    "Keras model can be evaluated with evaluate() function\n",
    "\n",
    "Evaluation results are contained in a list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "AAULjn-C2n6F",
    "outputId": "7adef48e-90f9-4bb9-d042-3dc548e985ff"
   },
   "outputs": [],
   "source": [
    "results = model.evaluate(X_test, y_test.values, verbose = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "iWPCJvmY2w9Z",
    "outputId": "2ffb160e-5f07-40c2-8314-97d9756a9ecd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'accuracy']\n",
      "[0.003805335954387563, 0.9992276]\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)\n",
    "print(results)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mFVCB24Zud4z"
   },
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_cls = model.predict_classes(X_test, batch_size=200, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "colab_type": "code",
    "id": "6ws8ykhbrAdy",
    "outputId": "75292028-2feb-4657-aaf7-00f9c1d6c8ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Model (Dropout): 0.99824446\n",
      "Recall_score: 0.54\n",
      "Precision_score: 0.8307692307692308\n",
      "F-score: 0.6545454545454545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[56851,    11],\n",
       "       [   46,    54]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Accuracy Model (Dropout): '+ str(results[1]))\n",
    "print('Recall_score: ' + str(recall_score(y_test,Y_pred_cls)))\n",
    "print('Precision_score: ' + str(precision_score(y_test, Y_pred_cls)))\n",
    "print('F-score: ' + str(f1_score(y_test,Y_pred_cls)))\n",
    "confusion_matrix(y_test, Y_pred_cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rjJpEpMrgDwc"
   },
   "source": [
    "#### Feel free to experiment with the model and get to better evaluation metric scores. \n",
    "Happy Learning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus - Lets Try an additional layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADAM Optimizer: https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/#:~:text=Adam%20is%20a%20replacement%20optimization,sparse%20gradients%20on%20noisy%20problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "29/64/32/16/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 64)                1920      \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 4,545\n",
      "Trainable params: 4,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 227845 samples\n",
      "Epoch 1/10\n",
      "227845/227845 [==============================] - 3s 13us/sample - loss: 0.0243 - accuracy: 0.9948\n",
      "Epoch 2/10\n",
      "227845/227845 [==============================] - 2s 9us/sample - loss: 0.0066 - accuracy: 0.9983\n",
      "Epoch 3/10\n",
      "227845/227845 [==============================] - 2s 9us/sample - loss: 0.0058 - accuracy: 0.9983\n",
      "Epoch 4/10\n",
      "227845/227845 [==============================] - 2s 9us/sample - loss: 0.0052 - accuracy: 0.9983\n",
      "Epoch 5/10\n",
      "227845/227845 [==============================] - 2s 10us/sample - loss: 0.0047 - accuracy: 0.9985\n",
      "Epoch 6/10\n",
      "227845/227845 [==============================] - 3s 11us/sample - loss: 0.0042 - accuracy: 0.9991\n",
      "Epoch 7/10\n",
      "227845/227845 [==============================] - 2s 11us/sample - loss: 0.0037 - accuracy: 0.9993\n",
      "Epoch 8/10\n",
      "227845/227845 [==============================] - 2s 10us/sample - loss: 0.0035 - accuracy: 0.9993\n",
      "Epoch 9/10\n",
      "227845/227845 [==============================] - 2s 10us/sample - loss: 0.0034 - accuracy: 0.9993\n",
      "Epoch 10/10\n",
      "227845/227845 [==============================] - 2s 10us/sample - loss: 0.0032 - accuracy: 0.9994\n"
     ]
    }
   ],
   "source": [
    "sgd = optimizers.Adam(lr = 0.001)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(64, input_shape = (29,), activation = 'relu'))\n",
    "model.add(Dense(32, activation = 'tanh'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer = sgd, loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(X_train, y_train.values, batch_size = 700, epochs = 10, verbose = 1)\n",
    "\n",
    "results = model.evaluate(X_test, y_test.values, verbose = 0)\n",
    "\n",
    "print(model.metrics_names)\n",
    "print(results)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Model (Dropout): 0.99942064\n",
      "Recall_score: 0.8\n",
      "Precision_score: 0.8602150537634409\n",
      "F-score: 0.8290155440414508\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[56849,    13],\n",
       "       [   20,    80]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_cls = model.predict_classes(X_test, batch_size=200, verbose=0)\n",
    "print('Accuracy Model (Dropout): '+ str(results[1]))\n",
    "print('Recall_score: ' + str(recall_score(y_test.values,Y_pred_cls)))\n",
    "print('Precision_score: ' + str(precision_score(y_test.values, Y_pred_cls)))\n",
    "print('F-score: ' + str(f1_score(y_test.values,Y_pred_cls)))\n",
    "confusion_matrix(y_test.values, Y_pred_cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus - Lets change the layer structure to 29/100/50/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_86 (Dense)             (None, 100)               3000      \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 8,101\n",
      "Trainable params: 8,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 227845 samples\n",
      "Epoch 1/10\n",
      "227845/227845 [==============================] - 4s 16us/sample - loss: 0.0268 - accuracy: 0.9983\n",
      "Epoch 2/10\n",
      "227845/227845 [==============================] - 3s 12us/sample - loss: 0.0265 - accuracy: 0.9983\n",
      "Epoch 3/10\n",
      "227845/227845 [==============================] - 3s 12us/sample - loss: 0.0265 - accuracy: 0.9983\n",
      "Epoch 4/10\n",
      "227845/227845 [==============================] - 3s 12us/sample - loss: 0.0265 - accuracy: 0.9983\n",
      "Epoch 5/10\n",
      "227845/227845 [==============================] - 3s 14us/sample - loss: 0.0265 - accuracy: 0.9983\n",
      "Epoch 6/10\n",
      "227845/227845 [==============================] - 3s 14us/sample - loss: 0.0265 - accuracy: 0.9983\n",
      "Epoch 7/10\n",
      "227845/227845 [==============================] - 4s 15us/sample - loss: 0.0265 - accuracy: 0.9983\n",
      "Epoch 8/10\n",
      "227845/227845 [==============================] - 3s 15us/sample - loss: 0.0265 - accuracy: 0.9983\n",
      "Epoch 9/10\n",
      "227845/227845 [==============================] - 4s 16us/sample - loss: 0.0265 - accuracy: 0.9983\n",
      "Epoch 10/10\n",
      "227845/227845 [==============================] - 3s 14us/sample - loss: 0.0265 - accuracy: 0.9983\n"
     ]
    }
   ],
   "source": [
    "sgd = optimizers.Adam(lr = 0.001)\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(100, input_shape = (29,), activation = 'tanh'))\n",
    "model.add(Dense(50, activation = 'tanh'))\n",
    "model.add(Dense(1, activation = 'tanh'))\n",
    "\n",
    "model.compile(optimizer = sgd, loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(X_train, y_train.values, batch_size = 700, epochs = 10, verbose = 1)\n",
    "\n",
    "results = model.evaluate(X_test, y_test.values, verbose = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Model (Dropout): 0.99899936\n",
      "Recall_score: 0.54\n",
      "Precision_score: 0.8307692307692308\n",
      "F-score: 0.6545454545454545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[56851,    11],\n",
       "       [   46,    54]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_cls = model.predict_classes(X_test, batch_size=200, verbose=0)\n",
    "print('Accuracy Model (Dropout): '+ str(results[1]))\n",
    "print('Recall_score: ' + str(recall_score(y_test.values,Y_pred_cls)))\n",
    "print('Precision_score: ' + str(precision_score(y_test.values, Y_pred_cls)))\n",
    "print('F-score: ' + str(f1_score(y_test.values,Y_pred_cls)))\n",
    "confusion_matrix(y_test.values, Y_pred_cls)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Mentor Session Case Study Notebook - Week 2",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
