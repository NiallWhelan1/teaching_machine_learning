{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Tensorflow_Mentor_Session_Case_Study_W1_Intro_to_NN.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"cells":[{"cell_type":"markdown","metadata":{"id":"5IIstFzwcpJE"},"source":["##Linear Regression using TensorFlow\n","\n","In this session, we will have a look at creating a linear regression model using tensorflow 2.0. Note that we already know the basics of linear regression and understand the implementation through sklearn. We will try to figure out how to do it using tensorflow tools that we have learnt.   \n","\n","\n","<i>Note that to keep this exercise simple and focused on tensorflow and its relevant functions, we will make a very simple model with very basic preprocessing.</i> "]},{"cell_type":"markdown","metadata":{"id":"EkKHyKfRFwYG"},"source":["#### Let us start with mounting our drive to be able to use the dataset stored in our dataset."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"14bgzjpOr0bI","executionInfo":{"status":"ok","timestamp":1619834965907,"user_tz":-480,"elapsed":22456,"user":{"displayName":"Niall Whelan","photoUrl":"","userId":"05564409335429355732"}},"outputId":"7c6819f6-8d86-48b5-d27a-ffe65e921b9a"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ykQXiPSPF_rf"},"source":["#### Let us install the latest version of tensorflow.\n"]},{"cell_type":"code","metadata":{"id":"tvNefLdVoZNz"},"source":["!pip install tensorflow==2.0.0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EvmX8Lp1GOSn"},"source":["##### Check the version of the installation"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ry8J8nA4ocet","executionInfo":{"status":"ok","timestamp":1619835073810,"user_tz":-480,"elapsed":2501,"user":{"displayName":"Niall Whelan","photoUrl":"","userId":"05564409335429355732"}},"outputId":"5946caeb-f74f-470e-ac1e-89e83b05bc40"},"source":["import tensorflow as tf\n","print(tf.__version__)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["2.0.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ycFapGk6GTSi"},"source":["Now Let us import out data and get it ready for modelling."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"hKt0pILMz_sn","executionInfo":{"status":"ok","timestamp":1619835154344,"user_tz":-480,"elapsed":1219,"user":{"displayName":"Niall Whelan","photoUrl":"","userId":"05564409335429355732"}},"outputId":"4649cebc-8a43-4408-ab0e-376418583012"},"source":["import pandas as pd\n","import numpy as np\n","import os\n","\n","os.chdir('/content/drive/My Drive/GreatLearning Mentoring/Week 17 - Artificial NNs')\n","\n","cars_data = pd.read_csv('usedcars.csv')\n","cars_data"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>year</th>\n","      <th>model</th>\n","      <th>price</th>\n","      <th>mileage</th>\n","      <th>color</th>\n","      <th>transmission</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2011</td>\n","      <td>SEL</td>\n","      <td>21992</td>\n","      <td>7413</td>\n","      <td>Yellow</td>\n","      <td>AUTO</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2011</td>\n","      <td>SEL</td>\n","      <td>20995</td>\n","      <td>10926</td>\n","      <td>Gray</td>\n","      <td>AUTO</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2011</td>\n","      <td>SEL</td>\n","      <td>19995</td>\n","      <td>7351</td>\n","      <td>Silver</td>\n","      <td>AUTO</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2011</td>\n","      <td>SEL</td>\n","      <td>17809</td>\n","      <td>11613</td>\n","      <td>Gray</td>\n","      <td>AUTO</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2012</td>\n","      <td>SE</td>\n","      <td>17500</td>\n","      <td>8367</td>\n","      <td>White</td>\n","      <td>AUTO</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>145</th>\n","      <td>2006</td>\n","      <td>SES</td>\n","      <td>6200</td>\n","      <td>95000</td>\n","      <td>Silver</td>\n","      <td>AUTO</td>\n","    </tr>\n","    <tr>\n","      <th>146</th>\n","      <td>2002</td>\n","      <td>SE</td>\n","      <td>5995</td>\n","      <td>87003</td>\n","      <td>Red</td>\n","      <td>AUTO</td>\n","    </tr>\n","    <tr>\n","      <th>147</th>\n","      <td>2000</td>\n","      <td>SE</td>\n","      <td>5980</td>\n","      <td>96841</td>\n","      <td>Red</td>\n","      <td>AUTO</td>\n","    </tr>\n","    <tr>\n","      <th>148</th>\n","      <td>2001</td>\n","      <td>SE</td>\n","      <td>4899</td>\n","      <td>151479</td>\n","      <td>Yellow</td>\n","      <td>AUTO</td>\n","    </tr>\n","    <tr>\n","      <th>149</th>\n","      <td>2000</td>\n","      <td>SE</td>\n","      <td>3800</td>\n","      <td>109259</td>\n","      <td>Red</td>\n","      <td>AUTO</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>150 rows × 6 columns</p>\n","</div>"],"text/plain":["     year model  price  mileage   color transmission\n","0    2011   SEL  21992     7413  Yellow         AUTO\n","1    2011   SEL  20995    10926    Gray         AUTO\n","2    2011   SEL  19995     7351  Silver         AUTO\n","3    2011   SEL  17809    11613    Gray         AUTO\n","4    2012    SE  17500     8367   White         AUTO\n","..    ...   ...    ...      ...     ...          ...\n","145  2006   SES   6200    95000  Silver         AUTO\n","146  2002    SE   5995    87003     Red         AUTO\n","147  2000    SE   5980    96841     Red         AUTO\n","148  2001    SE   4899   151479  Yellow         AUTO\n","149  2000    SE   3800   109259     Red         AUTO\n","\n","[150 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nX1zbyI75RMi","executionInfo":{"status":"ok","timestamp":1619835160625,"user_tz":-480,"elapsed":722,"user":{"displayName":"Niall Whelan","photoUrl":"","userId":"05564409335429355732"}},"outputId":"93893948-37b1-4bc4-8f0f-fdc44dd7160a"},"source":["cars_data.isna().sum()"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["year            0\n","model           0\n","price           0\n","mileage         0\n","color           0\n","transmission    0\n","dtype: int64"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":439},"id":"KuU03qQk1WfW","executionInfo":{"status":"ok","timestamp":1619835166631,"user_tz":-480,"elapsed":796,"user":{"displayName":"Niall Whelan","photoUrl":"","userId":"05564409335429355732"}},"outputId":"9220e457-0667-4557-e66d-e14a5a144b27"},"source":["#creating dummy variables for the categorical features\n","cars_data = pd.get_dummies(cars_data)\n","cars_data = cars_data.astype('float32') # we will need to convert the dataset to float in order to be able to convert it into tensors later.\n","cars_data\n"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>year</th>\n","      <th>price</th>\n","      <th>mileage</th>\n","      <th>model_SE</th>\n","      <th>model_SEL</th>\n","      <th>model_SES</th>\n","      <th>color_Black</th>\n","      <th>color_Blue</th>\n","      <th>color_Gold</th>\n","      <th>color_Gray</th>\n","      <th>color_Green</th>\n","      <th>color_Red</th>\n","      <th>color_Silver</th>\n","      <th>color_White</th>\n","      <th>color_Yellow</th>\n","      <th>transmission_AUTO</th>\n","      <th>transmission_MANUAL</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2011.0</td>\n","      <td>21992.0</td>\n","      <td>7413.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2011.0</td>\n","      <td>20995.0</td>\n","      <td>10926.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2011.0</td>\n","      <td>19995.0</td>\n","      <td>7351.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2011.0</td>\n","      <td>17809.0</td>\n","      <td>11613.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2012.0</td>\n","      <td>17500.0</td>\n","      <td>8367.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>145</th>\n","      <td>2006.0</td>\n","      <td>6200.0</td>\n","      <td>95000.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>146</th>\n","      <td>2002.0</td>\n","      <td>5995.0</td>\n","      <td>87003.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>147</th>\n","      <td>2000.0</td>\n","      <td>5980.0</td>\n","      <td>96841.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>148</th>\n","      <td>2001.0</td>\n","      <td>4899.0</td>\n","      <td>151479.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>149</th>\n","      <td>2000.0</td>\n","      <td>3800.0</td>\n","      <td>109259.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>150 rows × 17 columns</p>\n","</div>"],"text/plain":["       year    price  ...  transmission_AUTO  transmission_MANUAL\n","0    2011.0  21992.0  ...                1.0                  0.0\n","1    2011.0  20995.0  ...                1.0                  0.0\n","2    2011.0  19995.0  ...                1.0                  0.0\n","3    2011.0  17809.0  ...                1.0                  0.0\n","4    2012.0  17500.0  ...                1.0                  0.0\n","..      ...      ...  ...                ...                  ...\n","145  2006.0   6200.0  ...                1.0                  0.0\n","146  2002.0   5995.0  ...                1.0                  0.0\n","147  2000.0   5980.0  ...                1.0                  0.0\n","148  2001.0   4899.0  ...                1.0                  0.0\n","149  2000.0   3800.0  ...                1.0                  0.0\n","\n","[150 rows x 17 columns]"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xhihQaPY6LfN","executionInfo":{"status":"ok","timestamp":1619835187373,"user_tz":-480,"elapsed":1517,"user":{"displayName":"Niall Whelan","photoUrl":"","userId":"05564409335429355732"}},"outputId":"9cb7debc-8b3b-48de-b343-68270c39af65"},"source":["#getting the features and labels and finally splitting the test and train data.\n","\n","from sklearn.model_selection import train_test_split\n","X = cars_data.drop('price', axis = 1)\n","Y = cars_data['price']\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=1)\n","\n","#let us scale the data as features are on different scales which might be a problem while modelling\n","from sklearn import preprocessing\n","scaler = preprocessing.MinMaxScaler()\n","# MinMaxScalar has been used here. You can go ahead and use the other scalars available and chcek the effect on the results.\n","#fitting the transform on test and train separately\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","X_train"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.75      , 0.27928138, 0.        , ..., 0.        , 1.        ,\n","        0.        ],\n","       [0.58332825, 0.5233474 , 0.        , ..., 1.        , 0.        ,\n","        1.        ],\n","       [0.75      , 0.21721278, 1.        , ..., 0.        , 1.        ,\n","        0.        ],\n","       ...,\n","       [0.83332825, 0.20944397, 0.        , ..., 0.        , 1.        ,\n","        0.        ],\n","       [0.33332825, 0.6878496 , 1.        , ..., 0.        , 1.        ,\n","        0.        ],\n","       [0.83332825, 0.2253431 , 1.        , ..., 0.        , 1.        ,\n","        0.        ]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"PHjzg7vF5z0T","executionInfo":{"status":"ok","timestamp":1619835192276,"user_tz":-480,"elapsed":774,"user":{"displayName":"Niall Whelan","photoUrl":"","userId":"05564409335429355732"}}},"source":["\n","# let us now convert the data elements into tensors as we need tensors to be fed into different tensorflow based operations\n","#X-train and X_test were converted to numpy arrays while transformations while the other two need to be transformed into numpy arrays.\n","X_train=tf.convert_to_tensor(X_train)\n","y_train=tf.convert_to_tensor(y_train.values)\n","X_test=tf.convert_to_tensor(X_test)\n","y_test=tf.convert_to_tensor(y_test.values)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6ZEQAKqs66EO","executionInfo":{"status":"ok","timestamp":1619839031875,"user_tz":-480,"elapsed":1165,"user":{"displayName":"Niall Whelan","photoUrl":"","userId":"05564409335429355732"}},"outputId":"1691ddc9-d575-457f-e2b3-ccb63f8de112"},"source":["X_train.shape[1]"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["16"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"markdown","metadata":{"id":"mecQN830IGb9"},"source":["#### Let us try modelling now. We will use a few concepts covered in the practice exercise shared with the course material."]},{"cell_type":"code","metadata":{"id":"Uhitqoj2FH8U","executionInfo":{"status":"ok","timestamp":1619839285648,"user_tz":-480,"elapsed":861,"user":{"displayName":"Niall Whelan","photoUrl":"","userId":"05564409335429355732"}}},"source":["#### Setup variables\n","input_dim = X_train.shape[1]\n","output_dim = 1\n","learning_rate = 0.01"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"ErW3ULyd2X81","executionInfo":{"status":"ok","timestamp":1619839287435,"user_tz":-480,"elapsed":984,"user":{"displayName":"Niall Whelan","photoUrl":"","userId":"05564409335429355732"}}},"source":["# Let us initialize the weights and bias variables. \n","weights = tf.Variable(tf.zeros(shape=(input_dim, output_dim), dtype= tf.float32))\n","bias = tf.Variable(tf.ones(shape=(output_dim,), dtype= tf.float32))"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"_7XixfjC2rDd","executionInfo":{"status":"ok","timestamp":1619835243113,"user_tz":-480,"elapsed":778,"user":{"displayName":"Niall Whelan","photoUrl":"","userId":"05564409335429355732"}}},"source":["# Let us now define a function to train the model. We will call the other functions in function definition.\n","def predict(features):\n","    return tf.matmul(features, weights) + bias # note that the matmul is matrix multiplication and is needed for calculating predictions\n","\n","def compute_loss(y_true, predictions):\n","    return tf.reduce_mean(tf.square(y_true - predictions)) # mean square error\n","\n","def train(x, y):\n","    with tf.GradientTape() as tape:\n","        predictions = predict(x)\n","        loss = compute_loss(y, predictions)\n","        dloss_dw, dloss_db = tape.gradient(loss, [weights, bias]  ) #note that we can pass lists as well here. (dw = weights, db = bias)\n","    weights.assign_sub(learning_rate * dloss_dw)\n","    bias.assign_sub(learning_rate * dloss_db)\n","    return loss\n"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pcVzQimxJJe2"},"source":["#### Let us now, call the train function with 50 epochs"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rWFBawhVoM4j","executionInfo":{"status":"ok","timestamp":1619835307013,"user_tz":-480,"elapsed":1230,"user":{"displayName":"Niall Whelan","photoUrl":"","userId":"05564409335429355732"}},"outputId":"70f873a5-5bd0-4242-f53c-f4b76f0f8813"},"source":["for epoch in range(50):\n","    loss = train(X_train, y_train)\n","    print('Epoch %d: Loss = %.1f' % (epoch, float(loss)))\n"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Epoch 0: Loss = 176731120.0\n","Epoch 1: Loss = 157933824.0\n","Epoch 2: Loss = 141282496.0\n","Epoch 3: Loss = 126532168.0\n","Epoch 4: Loss = 113465608.0\n","Epoch 5: Loss = 101890464.0\n","Epoch 6: Loss = 91636368.0\n","Epoch 7: Loss = 82552456.0\n","Epoch 8: Loss = 74505024.0\n","Epoch 9: Loss = 67375672.0\n","Epoch 10: Loss = 61059540.0\n","Epoch 11: Loss = 55463724.0\n","Epoch 12: Loss = 50505948.0\n","Epoch 13: Loss = 46113352.0\n","Epoch 14: Loss = 42221360.0\n","Epoch 15: Loss = 38772792.0\n","Epoch 16: Loss = 35717000.0\n","Epoch 17: Loss = 33009130.0\n","Epoch 18: Loss = 30609446.0\n","Epoch 19: Loss = 28482742.0\n","Epoch 20: Loss = 26597858.0\n","Epoch 21: Loss = 24927154.0\n","Epoch 22: Loss = 23446196.0\n","Epoch 23: Loss = 22133294.0\n","Epoch 24: Loss = 20969272.0\n","Epoch 25: Loss = 19937130.0\n","Epoch 26: Loss = 19021806.0\n","Epoch 27: Loss = 18209964.0\n","Epoch 28: Loss = 17489794.0\n","Epoch 29: Loss = 16850832.0\n","Epoch 30: Loss = 16283805.0\n","Epoch 31: Loss = 15780510.0\n","Epoch 32: Loss = 15333666.0\n","Epoch 33: Loss = 14936839.0\n","Epoch 34: Loss = 14584323.0\n","Epoch 35: Loss = 14271066.0\n","Epoch 36: Loss = 13992586.0\n","Epoch 37: Loss = 13744920.0\n","Epoch 38: Loss = 13524554.0\n","Epoch 39: Loss = 13328377.0\n","Epoch 40: Loss = 13153640.0\n","Epoch 41: Loss = 12997894.0\n","Epoch 42: Loss = 12858982.0\n","Epoch 43: Loss = 12734984.0\n","Epoch 44: Loss = 12624207.0\n","Epoch 45: Loss = 12525152.0\n","Epoch 46: Loss = 12436473.0\n","Epoch 47: Loss = 12357014.0\n","Epoch 48: Loss = 12285709.0\n","Epoch 49: Loss = 12221641.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iGhG6KM-4KIE","executionInfo":{"status":"ok","timestamp":1619835313253,"user_tz":-480,"elapsed":801,"user":{"displayName":"Niall Whelan","photoUrl":"","userId":"05564409335429355732"}},"outputId":"3f1fb9f5-1c5d-49ee-9164-f3a672eff3ab"},"source":["print('Final Weights after 50 epochs:')\n","print(weights)\n","print('###############################################################################')\n","\n","print('Final Bias after 50 epochs:')\n","print(bias)\n","print('###############################################################################')\n"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Final Weights after 50 epochs:\n","<tf.Variable 'Variable:0' shape=(16, 1) dtype=float32, numpy=\n","array([[3008.1316  ],\n","       [1190.5148  ],\n","       [2035.1709  ],\n","       [ 605.12933 ],\n","       [1614.7789  ],\n","       [ 831.85315 ],\n","       [ 515.2115  ],\n","       [  34.478077],\n","       [ 466.3804  ],\n","       [ 203.20662 ],\n","       [ 746.81555 ],\n","       [ 910.93    ],\n","       [ 410.437   ],\n","       [ 135.7667  ],\n","       [3421.83    ],\n","       [ 833.2481  ]], dtype=float32)>\n","###############################################################################\n","Final Bias after 50 epochs:\n","<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([4256.079], dtype=float32)>\n","###############################################################################\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bdgve0a7Jwwq"},"source":["#### Let us now test our model on the test data and predict on the test data."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zyXnEJiyqNjv","executionInfo":{"status":"ok","timestamp":1619835328506,"user_tz":-480,"elapsed":751,"user":{"displayName":"Niall Whelan","photoUrl":"","userId":"05564409335429355732"}},"outputId":"be53d485-6b61-4734-b520-9177a6efd40b"},"source":["test_predictions = tf.matmul(X_test, weights) + bias\n","print(compute_loss(y_test, test_predictions))"],"execution_count":21,"outputs":[{"output_type":"stream","text":["tf.Tensor(8548196.0, shape=(), dtype=float32)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"857fnFanv8WZ","executionInfo":{"status":"ok","timestamp":1619836193373,"user_tz":-480,"elapsed":708,"user":{"displayName":"Niall Whelan","photoUrl":"","userId":"05564409335429355732"}},"outputId":"f9e760e3-a88c-4e31-f015-8122c46f516e"},"source":["test_predictions"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: id=1881, shape=(30, 1), dtype=float32, numpy=\n","array([[12966.248],\n","       [12759.732],\n","       [11598.596],\n","       [11823.011],\n","       [12167.282],\n","       [10588.252],\n","       [12544.059],\n","       [13192.689],\n","       [11679.381],\n","       [13533.48 ],\n","       [13303.452],\n","       [11865.228],\n","       [12738.202],\n","       [12878.569],\n","       [13292.344],\n","       [10183.004],\n","       [12652.132],\n","       [12997.48 ],\n","       [10452.417],\n","       [11850.39 ],\n","       [12616.388],\n","       [10689.47 ],\n","       [12982.405],\n","       [12955.671],\n","       [12863.805],\n","       [ 9874.346],\n","       [11986.701],\n","       [12172.322],\n","       [11634.078],\n","       [11628.225]], dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TrIAT2BOwu4L","executionInfo":{"status":"ok","timestamp":1619836204945,"user_tz":-480,"elapsed":745,"user":{"displayName":"Niall Whelan","photoUrl":"","userId":"05564409335429355732"}},"outputId":"ad1523e7-bbb1-4fab-dc56-44df79e6e5f9"},"source":["y_test"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: id=3, shape=(30,), dtype=float32, numpy=\n","array([16000., 12507., 13584., 15999.,  8800., 13995.,  6995., 14499.,\n","       14999., 10717., 12780., 17495., 11999., 14275., 13383., 14677.,\n","       12988., 13950., 14995., 14990., 12992., 12995., 13384., 14761.,\n","        9995., 12500., 14992., 15992., 13663.,  5995.], dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"markdown","metadata":{"id":"X8xCBIesKGbY"},"source":["We learnt creating a very simple linear regression model on cars data and predicted prices. \n","\n","Though, we could have done an extensive EDA and further improved the model but we have focused on tensorflow and its operations.\n","\n","<i>Happy Learning!</i>"]}]}